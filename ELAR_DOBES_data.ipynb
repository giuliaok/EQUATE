{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELAR_archive = 'https://www.elararchive.org/uncategorized/SO_5f038640-311d-4296-a3e9-502e8a18f5b7/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = requests.get(ELAR_archive).text\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find all <p> tags with class=\"facet-title\" and title=\"Language\"\n",
    "facet_titles = soup.find_all('div', class_='facet-group')\n",
    "language_facets = [facet for facet in facet_titles if 'language' in facet.get('facet-name', '')]\n",
    "\n",
    "input_ids = []\n",
    "\n",
    "    # Loop through each language facet title to find its associated <ul> tag\n",
    "for facet_title in language_facets:\n",
    "    # Find the <fieldset> tag within this <p> tag\n",
    "    fieldset_tag = facet_title.find_next('fieldset')\n",
    "    \n",
    "    if fieldset_tag:\n",
    "        # Find all <input> tags within this <fieldset> tag\n",
    "        input_tags = fieldset_tag.find_all('input')\n",
    "        # Extract and store ids\n",
    "        ids = [input_tag.get('id') for input_tag in input_tags]\n",
    "        input_ids.extend(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!Xun',\n",
       " \"'Olekha\",\n",
       " \"=X'ao-||'aen\",\n",
       " 'Abom',\n",
       " 'Abui',\n",
       " 'Adyumba',\n",
       " 'Ahamb',\n",
       " 'A Hou',\n",
       " 'Ainu',\n",
       " 'Aisi',\n",
       " 'Ajumbu',\n",
       " 'Akan',\n",
       " 'Akha',\n",
       " 'Akuntsú',\n",
       " 'Alipur Village Sign Language (AVSL)',\n",
       " 'Allang',\n",
       " 'Ambel',\n",
       " 'Amurdak',\n",
       " 'Anal',\n",
       " 'Aneityum, Sie, Raga (Hano), Namakura, Southwest Tanna, North Tanna',\n",
       " 'Animere',\n",
       " 'Anindilyakwa',\n",
       " 'Antia Whistling Language',\n",
       " 'Apurinã',\n",
       " 'Arammba',\n",
       " 'Arandic',\n",
       " 'Arandic      ',\n",
       " 'Araona',\n",
       " 'Arapaho',\n",
       " 'Arawak',\n",
       " 'Archaic Akha',\n",
       " 'Archi',\n",
       " 'Aren',\n",
       " 'Aro',\n",
       " 'Arta',\n",
       " 'Asheninka Perene',\n",
       " 'Asimjeeg Datooga',\n",
       " 'Asur',\n",
       " 'Atchin (Uripiv-Wala-Rano-Atchin)',\n",
       " 'Auslan',\n",
       " 'Australian Irish Sign Language',\n",
       " 'Avatime',\n",
       " 'Awiakay',\n",
       " 'Awu Alaya',\n",
       " 'Ayere',\n",
       " 'Ayoreo',\n",
       " 'Ayuru',\n",
       " 'Ayutla Mixe',\n",
       " 'Baa',\n",
       " \"Baba'1\",\n",
       " 'Babanki Ritual Speech',\n",
       " 'Badaga',\n",
       " 'Bafia',\n",
       " 'Bafut',\n",
       " 'Baga Mandori',\n",
       " 'Bainouk',\n",
       " 'Bajjika',\n",
       " 'Balochi',\n",
       " 'Baluchi',\n",
       " 'Banam Bay Area Language',\n",
       " 'Baram',\n",
       " 'Brahui',\n",
       " 'Buu',\n",
       " \"Cha'palaa\",\n",
       " 'Chatino Sign Language, San Juan Quiahije',\n",
       " 'Cofán',\n",
       " 'Dalabon',\n",
       " 'Dari',\n",
       " 'Eastern Khanty',\n",
       " 'English',\n",
       " 'Ersu',\n",
       " 'German',\n",
       " 'Golpa',\n",
       " 'Haliti',\n",
       " 'Ibibio',\n",
       " 'Kam',\n",
       " 'Khengkha',\n",
       " 'Korean',\n",
       " 'Koryak',\n",
       " 'Kotiria',\n",
       " 'Kun-barlang',\n",
       " 'Kurtöp',\n",
       " 'Matlatzinca',\n",
       " 'Meakambut',\n",
       " 'Mehri',\n",
       " 'Negidal',\n",
       " 'N|uu',\n",
       " 'Otomi',\n",
       " 'Paresi',\n",
       " 'Russian',\n",
       " 'Sasi',\n",
       " 'Teleut',\n",
       " 'Tseltal',\n",
       " 'Upper Napo Kichwa',\n",
       " 'Urarina',\n",
       " 'Vute',\n",
       " \"Wa'ikhana\",\n",
       " 'Wik Mungkan',\n",
       " 'Yan-nhaŋu',\n",
       " 'Zauzou']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"elan.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    elan_ul = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Name  \\\n",
      "0                          Jakarta Indonesian   \n",
      "1           Jakarta Indonesian Child Language   \n",
      "2                       Turkish Sign Language   \n",
      "3    Jakarta Indonesian Child-Directed Speech   \n",
      "4                             infant babbling   \n",
      "..                                        ...   \n",
      "785           Zapotec, Santa Maria Albarradas   \n",
      "786              Zapotec, Santiago Lachiguiri   \n",
      "787                      Zapotec, Suchixtepec   \n",
      "788                     Zapotec, Tabaa Elodia   \n",
      "789                            Zapotec, Talea   \n",
      "\n",
      "                                                  Href  Count  \n",
      "0    https://archive.mpi.nl/tla/islandora/object/la...   1409  \n",
      "1    https://archive.mpi.nl/tla/islandora/object/la...   1338  \n",
      "2    https://archive.mpi.nl/tla/islandora/object/la...   1232  \n",
      "3    https://archive.mpi.nl/tla/islandora/object/la...   1183  \n",
      "4    https://archive.mpi.nl/tla/islandora/object/la...   1157  \n",
      "..                                                 ...    ...  \n",
      "785  https://archive.mpi.nl/tla/islandora/object/la...      1  \n",
      "786  https://archive.mpi.nl/tla/islandora/object/la...      1  \n",
      "787  https://archive.mpi.nl/tla/islandora/object/la...      1  \n",
      "788  https://archive.mpi.nl/tla/islandora/object/la...      1  \n",
      "789  https://archive.mpi.nl/tla/islandora/object/la...      1  \n",
      "\n",
      "[790 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(elan_ul, \"html.parser\")\n",
    "\n",
    "# Find all <li> tags\n",
    "li_tags = soup.find_all(\"li\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "names = []\n",
    "hrefs = []\n",
    "counts = []\n",
    "\n",
    "# Extract name, href, and count from each <li> tag\n",
    "for li in li_tags:\n",
    "    a_tag = li.find(\"a\")\n",
    "    if a_tag:\n",
    "        name = a_tag.get_text(strip=True)\n",
    "        href = \"https://archive.mpi.nl\" + a_tag[\"href\"]\n",
    "        count = int(li.find(\"span\", class_=\"count\").get_text(strip=True).strip(\"()\"))\n",
    "        names.append(name)\n",
    "        hrefs.append(href)\n",
    "        counts.append(count)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"Name\": names, \"Href\": hrefs, \"Count\": counts})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOBES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dobes.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    dobes_ul = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name                                               Href  Count\n",
      "0        English  https://archive.mpi.nl/tla/islandora/object/tl...   2883\n",
      "1        Spanish  https://archive.mpi.nl/tla/islandora/object/tl...   2738\n",
      "2       Yurakaré  https://archive.mpi.nl/tla/islandora/object/tl...   1645\n",
      "3         Beaver  https://archive.mpi.nl/tla/islandora/object/tl...   1042\n",
      "4     Portuguese  https://archive.mpi.nl/tla/islandora/object/tl...    925\n",
      "..           ...                                                ...    ...\n",
      "301      Tzeltal  https://archive.mpi.nl/tla/islandora/object/tl...      1\n",
      "302        Waurá  https://archive.mpi.nl/tla/islandora/object/tl...      1\n",
      "303  Wára (Wära)  https://archive.mpi.nl/tla/islandora/object/tl...      1\n",
      "304   Yawalapití  https://archive.mpi.nl/tla/islandora/object/tl...      1\n",
      "305         |Gwi  https://archive.mpi.nl/tla/islandora/object/tl...      1\n",
      "\n",
      "[306 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Parse the HTML content\n",
    "dobes_soup = BeautifulSoup(dobes_ul, \"html.parser\")\n",
    "\n",
    "# Find all <li> tags\n",
    "li_tags = dobes_soup.find_all(\"li\")\n",
    "\n",
    "# Initialize lists to store data\n",
    "names = []\n",
    "hrefs = []\n",
    "counts = []\n",
    "\n",
    "# Extract name, href, and count from each <li> tag\n",
    "for li in li_tags:\n",
    "    a_tag = li.find(\"a\")\n",
    "    if a_tag:\n",
    "        name = a_tag.get_text(strip=True)\n",
    "        href = \"https://archive.mpi.nl\" + a_tag[\"href\"]\n",
    "        count = int(li.find(\"span\", class_=\"count\").get_text(strip=True).strip(\"()\"))\n",
    "        names.append(name)\n",
    "        hrefs.append(href)\n",
    "        counts.append(count)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"Name\": names, \"Href\": hrefs, \"Count\": counts})\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eq_pap_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
