{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe get also likes and uses..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_languages_link = 'https://huggingface.co/languages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_huggingface_languages(url):\n",
    "    html_text = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    # Initialize lists to store extracted data\n",
    "    languages = []\n",
    "    iso_codes = []\n",
    "    datasets_links = []\n",
    "    models_links = []\n",
    "    datasets_numbers = []\n",
    "    model_numbers = []\n",
    "\n",
    "    # Extract data from each row of the table\n",
    "    for row in soup.find_all('tr'):\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) > 0:  # Ensure it's not the header row\n",
    "            language = cols[0].get_text(strip=True)\n",
    "            iso_code = cols[1].find('code').get_text(strip=True)\n",
    "            datasets_link = \"https://huggingface.co\" + cols[2].find('a')['href']\n",
    "            models_link = \"https://huggingface.co\" + cols[3].find('a')['href']\n",
    "            datasets_number = int(cols[2].find('a').get_text(strip=True).replace(',', ''))\n",
    "            model_number = int(cols[3].find('a').get_text(strip=True).replace(',', ''))\n",
    "            \n",
    "            # Append data to lists\n",
    "            languages.append(language)\n",
    "            iso_codes.append(iso_code)\n",
    "            datasets_links.append(datasets_link)\n",
    "            models_links.append(models_link)\n",
    "            datasets_numbers.append(datasets_number)\n",
    "            model_numbers.append(model_number)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Language': languages,\n",
    "        'ISO Code': iso_codes,\n",
    "        'Datasets Link': datasets_links,\n",
    "        'Models Link': models_links,\n",
    "        'Datasets Number': datasets_numbers,\n",
    "        'Model Number': model_numbers\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_huggingface_languages(huggingface_languages_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>ISO Code</th>\n",
       "      <th>Datasets Link</th>\n",
       "      <th>Models Link</th>\n",
       "      <th>Datasets Number</th>\n",
       "      <th>Model Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EnglishEnglish</td>\n",
       "      <td>en</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=en</td>\n",
       "      <td>7792</td>\n",
       "      <td>34087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chinese中文</td>\n",
       "      <td>zh</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=zh</td>\n",
       "      <td>922</td>\n",
       "      <td>3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FrenchFrançais</td>\n",
       "      <td>fr</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=fr</td>\n",
       "      <td>823</td>\n",
       "      <td>3237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SpanishEspañol</td>\n",
       "      <td>es</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=es</td>\n",
       "      <td>646</td>\n",
       "      <td>2523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RussianРусский</td>\n",
       "      <td>ru</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=ru</td>\n",
       "      <td>620</td>\n",
       "      <td>1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>Peruvian Sign Language</td>\n",
       "      <td>prl</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=prl</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>Venezuelan Sign Language</td>\n",
       "      <td>vsl</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=vsl</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>Sabah Malay</td>\n",
       "      <td>msi</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=msi</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>Mexican Sign Language</td>\n",
       "      <td>mfs</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=mfs</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>Tunzu</td>\n",
       "      <td>dza</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=dza</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2046 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Language ISO Code  \\\n",
       "0               EnglishEnglish       en   \n",
       "1                    Chinese中文       zh   \n",
       "2               FrenchFrançais       fr   \n",
       "3               SpanishEspañol       es   \n",
       "4               RussianРусский       ru   \n",
       "...                        ...      ...   \n",
       "2041    Peruvian Sign Language      prl   \n",
       "2042  Venezuelan Sign Language      vsl   \n",
       "2043               Sabah Malay      msi   \n",
       "2044     Mexican Sign Language      mfs   \n",
       "2045                     Tunzu      dza   \n",
       "\n",
       "                                          Datasets Link  \\\n",
       "0     https://huggingface.co/datasets?language=langu...   \n",
       "1     https://huggingface.co/datasets?language=langu...   \n",
       "2     https://huggingface.co/datasets?language=langu...   \n",
       "3     https://huggingface.co/datasets?language=langu...   \n",
       "4     https://huggingface.co/datasets?language=langu...   \n",
       "...                                                 ...   \n",
       "2041  https://huggingface.co/datasets?language=langu...   \n",
       "2042  https://huggingface.co/datasets?language=langu...   \n",
       "2043  https://huggingface.co/datasets?language=langu...   \n",
       "2044  https://huggingface.co/datasets?language=langu...   \n",
       "2045  https://huggingface.co/datasets?language=langu...   \n",
       "\n",
       "                                     Models Link  Datasets Number  \\\n",
       "0      https://huggingface.co/models?language=en             7792   \n",
       "1      https://huggingface.co/models?language=zh              922   \n",
       "2      https://huggingface.co/models?language=fr              823   \n",
       "3      https://huggingface.co/models?language=es              646   \n",
       "4      https://huggingface.co/models?language=ru              620   \n",
       "...                                          ...              ...   \n",
       "2041  https://huggingface.co/models?language=prl                1   \n",
       "2042  https://huggingface.co/models?language=vsl                1   \n",
       "2043  https://huggingface.co/models?language=msi                1   \n",
       "2044  https://huggingface.co/models?language=mfs                1   \n",
       "2045  https://huggingface.co/models?language=dza                1   \n",
       "\n",
       "      Model Number  \n",
       "0            34087  \n",
       "1             3495  \n",
       "2             3237  \n",
       "3             2523  \n",
       "4             1752  \n",
       "...            ...  \n",
       "2041             3  \n",
       "2042             2  \n",
       "2043            14  \n",
       "2044             3  \n",
       "2045             3  \n",
       "\n",
       "[2046 rows x 6 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_huggingface_datasets(dataset_url):\n",
    "    dataset_request = requests.get(dataset_url).text\n",
    "    dataset_soup = BeautifulSoup(dataset_request, 'html.parser')\n",
    "    # Extract text and href attributes for all articles\n",
    "    articles_data = []\n",
    "    articles = dataset_soup.find_all('article')\n",
    "    for article in articles:\n",
    "        text = article.h4.text.strip()\n",
    "        href = article.a['href']\n",
    "        div = article.find('div').get_text(strip=True)\n",
    "        #this part does not work very well yet...(the downloads and likes one)\n",
    "        likes = re.findall(r'\\b\\d+\\b', div)[0]\n",
    "        downloads = re.findall(r'\\b\\d+\\b', div)[1]\n",
    "        articles_data.append({'dataset': text, 'dataset_url': href, 'downloads':downloads, 'likes':likes})\n",
    "        \n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(articles_data)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stats = process_huggingface_datasets('https://huggingface.co/datasets?language=language:ofs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset_url</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tatoeba</td>\n",
       "      <td>/datasets/tatoeba</td>\n",
       "      <td>967</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lbourdois/language_tags</td>\n",
       "      <td>/datasets/lbourdois/language_tags</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lbourdois/panlex</td>\n",
       "      <td>/datasets/lbourdois/panlex</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dataset                        dataset_url downloads likes\n",
       "0                  tatoeba                  /datasets/tatoeba       967    18\n",
       "1  lbourdois/language_tags  /datasets/lbourdois/language_tags         2     7\n",
       "2         lbourdois/panlex         /datasets/lbourdois/panlex         1     6"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "longer_dataset_stats = process_huggingface_datasets('https://huggingface.co/datasets?language=language:or')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset_url</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikimedia/wikipedia</td>\n",
       "      <td>/datasets/wikimedia/wikipedia</td>\n",
       "      <td>332</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>opus100</td>\n",
       "      <td>/datasets/opus100</td>\n",
       "      <td>75</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>/datasets/wikipedia</td>\n",
       "      <td>398</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wikimedia/wikisource</td>\n",
       "      <td>/datasets/wikimedia/wikisource</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook/belebele</td>\n",
       "      <td>/datasets/facebook/belebele</td>\n",
       "      <td>2023</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mozilla-foundation/common_voice_16_0</td>\n",
       "      <td>/datasets/mozilla-foundation/common_voice_16_0</td>\n",
       "      <td>2023</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cc100</td>\n",
       "      <td>/datasets/cc100</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>common_voice</td>\n",
       "      <td>/datasets/common_voice</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oscar</td>\n",
       "      <td>/datasets/oscar</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>qed_amara</td>\n",
       "      <td>/datasets/qed_amara</td>\n",
       "      <td>220</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tatoeba</td>\n",
       "      <td>/datasets/tatoeba</td>\n",
       "      <td>967</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>olm/wikipedia</td>\n",
       "      <td>/datasets/olm/wikipedia</td>\n",
       "      <td>27</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>graelo/wikipedia</td>\n",
       "      <td>/datasets/graelo/wikipedia</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mozilla-foundation/common_voice_16_1</td>\n",
       "      <td>/datasets/mozilla-foundation/common_voice_16_1</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ccaligned_multilingual</td>\n",
       "      <td>/datasets/ccaligned_multilingual</td>\n",
       "      <td>474</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>indic_glue</td>\n",
       "      <td>/datasets/indic_glue</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>kde4</td>\n",
       "      <td>/datasets/kde4</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mkb</td>\n",
       "      <td>/datasets/mkb</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>opus_gnome</td>\n",
       "      <td>/datasets/opus_gnome</td>\n",
       "      <td>542</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>opus_ubuntu</td>\n",
       "      <td>/datasets/opus_ubuntu</td>\n",
       "      <td>566</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pib</td>\n",
       "      <td>/datasets/pib</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>wikiann</td>\n",
       "      <td>/datasets/wikiann</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>wili_2018</td>\n",
       "      <td>/datasets/wili_2018</td>\n",
       "      <td>206</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Harveenchadha/indic-voice</td>\n",
       "      <td>/datasets/Harveenchadha/indic-voice</td>\n",
       "      <td>2023</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ai4bharat/samanantar</td>\n",
       "      <td>/datasets/ai4bharat/samanantar</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gsarti/flores_101</td>\n",
       "      <td>/datasets/gsarti/flores_101</td>\n",
       "      <td>2022</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>oscar-corpus/OSCAR-2109</td>\n",
       "      <td>/datasets/oscar-corpus/OSCAR-2109</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MLCommons/ml_spoken_words</td>\n",
       "      <td>/datasets/MLCommons/ml_spoken_words</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sil-ai/bloom-lm</td>\n",
       "      <td>/datasets/sil-ai/bloom-lm</td>\n",
       "      <td>2022</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ai4bharat/IndicParaphrase</td>\n",
       "      <td>/datasets/ai4bharat/IndicParaphrase</td>\n",
       "      <td>2022</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 dataset  \\\n",
       "0                    wikimedia/wikipedia   \n",
       "1                                opus100   \n",
       "2                              wikipedia   \n",
       "3                   wikimedia/wikisource   \n",
       "4                      facebook/belebele   \n",
       "5   mozilla-foundation/common_voice_16_0   \n",
       "6                                  cc100   \n",
       "7                           common_voice   \n",
       "8                                  oscar   \n",
       "9                              qed_amara   \n",
       "10                               tatoeba   \n",
       "11                         olm/wikipedia   \n",
       "12                      graelo/wikipedia   \n",
       "13  mozilla-foundation/common_voice_16_1   \n",
       "14                ccaligned_multilingual   \n",
       "15                            indic_glue   \n",
       "16                                  kde4   \n",
       "17                                   mkb   \n",
       "18                            opus_gnome   \n",
       "19                           opus_ubuntu   \n",
       "20                                   pib   \n",
       "21                               wikiann   \n",
       "22                             wili_2018   \n",
       "23             Harveenchadha/indic-voice   \n",
       "24                  ai4bharat/samanantar   \n",
       "25                     gsarti/flores_101   \n",
       "26               oscar-corpus/OSCAR-2109   \n",
       "27             MLCommons/ml_spoken_words   \n",
       "28                       sil-ai/bloom-lm   \n",
       "29             ai4bharat/IndicParaphrase   \n",
       "\n",
       "                                       dataset_url downloads likes  \n",
       "0                    /datasets/wikimedia/wikipedia       332     9  \n",
       "1                                /datasets/opus100        75    13  \n",
       "2                              /datasets/wikipedia       398    18  \n",
       "3                   /datasets/wikimedia/wikisource      2023     8  \n",
       "4                      /datasets/facebook/belebele      2023    15  \n",
       "5   /datasets/mozilla-foundation/common_voice_16_0      2023    21  \n",
       "6                                  /datasets/cc100         4    18  \n",
       "7                           /datasets/common_voice       120     5  \n",
       "8                                  /datasets/oscar        17    18  \n",
       "9                              /datasets/qed_amara       220    18  \n",
       "10                               /datasets/tatoeba       967    18  \n",
       "11                         /datasets/olm/wikipedia        27   195  \n",
       "12                      /datasets/graelo/wikipedia      2023    10  \n",
       "13  /datasets/mozilla-foundation/common_voice_16_1        32    16  \n",
       "14                /datasets/ccaligned_multilingual       474    18  \n",
       "15                            /datasets/indic_glue         3     4  \n",
       "16                                  /datasets/kde4         2    18  \n",
       "17                                   /datasets/mkb         1    18  \n",
       "18                            /datasets/opus_gnome       542    18  \n",
       "19                           /datasets/opus_ubuntu       566    18  \n",
       "20                                   /datasets/pib         2    18  \n",
       "21                               /datasets/wikiann        23    18  \n",
       "22                             /datasets/wili_2018       206    18  \n",
       "23             /datasets/Harveenchadha/indic-voice      2023    26  \n",
       "24                  /datasets/ai4bharat/samanantar      2022     7  \n",
       "25                     /datasets/gsarti/flores_101      2022    27  \n",
       "26               /datasets/oscar-corpus/OSCAR-2109      2022     8  \n",
       "27             /datasets/MLCommons/ml_spoken_words      2022     6  \n",
       "28                       /datasets/sil-ai/bloom-lm      2022    21  \n",
       "29             /datasets/ai4bharat/IndicParaphrase      2022    13  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_dataset_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_next_page_url(soup):\n",
    "    sections = soup.find_all('section')[-1]\n",
    "    if sections:\n",
    "        next_page_link = last_section.find('nav').find_all('a')[-1].get('href')\n",
    "    if next_page_link:\n",
    "        return next_page_link\n",
    "    else:\n",
    "        print('no href found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = extract_next_page_url(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?language=language:or&p=1&sort=trending'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data_per_language(language_url):\n",
    "    language_file = requests.get(language_url)\n",
    "    if language_file.status_code == 200:\n",
    "        soup = BeautifulSoup(language_file.text, 'html.parser')\n",
    "        next_page_url = extract_next_page_url(soup) \n",
    "        while next_page_url:\n",
    "            next_file = requests.get(\"https://huggingface.co\" + next_page_url)\n",
    "            if language_file.status_code == 200:\n",
    "                new_soup = BeautifulSoup(language_file.text, 'html.parser')\n",
    "                return new_soup\n",
    "            else:\n",
    "                print('Error: Unable to fetch language URL:', language_url)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_datasets(soup):\n",
    "    articles_data = []\n",
    "    articles = soup.find_all('article')\n",
    "    for article in articles:\n",
    "        text = article.h4.text.strip()\n",
    "        href = article.a['href']\n",
    "        div = article.find('div').get_text(strip=True)\n",
    "        likes = re.findall(r'\\b\\d+k?\\b', div)[-2]\n",
    "        downloads = re.findall(r'\\b\\d+k?\\b', div)[-1]\n",
    "        articles_data.append({'dataset': text, 'dataset_url': href, 'downloads':downloads, 'likes':likes})\n",
    "    \n",
    "    df = pd.DataFrame(articles_data)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_datasets(BeautifulSoup(trial, 'html.parser'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = extract_datasets(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset_url</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tatoeba</td>\n",
       "      <td>/datasets/tatoeba</td>\n",
       "      <td>23</td>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lbourdois/language_tags</td>\n",
       "      <td>/datasets/lbourdois/language_tags</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lbourdois/panlex</td>\n",
       "      <td>/datasets/lbourdois/panlex</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dataset                        dataset_url downloads likes\n",
       "0                  tatoeba                  /datasets/tatoeba        23   967\n",
       "1  lbourdois/language_tags  /datasets/lbourdois/language_tags         2     7\n",
       "2         lbourdois/panlex         /datasets/lbourdois/panlex         1     6"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = find_data_per_language('https://huggingface.co/datasets?language=language:ofs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
