{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find likes and donwloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_languages_link = 'https://huggingface.co/languages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_huggingface_languages(url):\n",
    "    html_text = requests.get(url).text\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    # Initialize lists to store extracted data\n",
    "    languages = []\n",
    "    iso_codes = []\n",
    "    datasets_links = []\n",
    "    models_links = []\n",
    "    datasets_numbers = []\n",
    "    model_numbers = []\n",
    "\n",
    "    # Extract data from each row of the table\n",
    "    for row in soup.find_all('tr'):\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) > 0:  # Ensure it's not the header row\n",
    "            language = cols[0].get_text(strip=True)\n",
    "            iso_code = cols[1].find('code').get_text(strip=True)\n",
    "            datasets_link = \"https://huggingface.co\" + cols[2].find('a')['href']\n",
    "            models_link = \"https://huggingface.co\" + cols[3].find('a')['href']\n",
    "            datasets_number = int(cols[2].find('a').get_text(strip=True).replace(',', ''))\n",
    "            model_number = int(cols[3].find('a').get_text(strip=True).replace(',', ''))\n",
    "            \n",
    "            # Append data to lists\n",
    "            languages.append(language)\n",
    "            iso_codes.append(iso_code)\n",
    "            datasets_links.append(datasets_link)\n",
    "            models_links.append(models_link)\n",
    "            datasets_numbers.append(datasets_number)\n",
    "            model_numbers.append(model_number)\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Language': languages,\n",
    "        'ISO Code': iso_codes,\n",
    "        'Datasets Link': datasets_links,\n",
    "        'Models Link': models_links,\n",
    "        'Datasets Number': datasets_numbers,\n",
    "        'Model Number': model_numbers\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def process_huggingface_datasets(dataset_url):\n",
    "    dataset_request = requests.get(dataset_url).text\n",
    "    dataset_soup = BeautifulSoup(dataset_request, 'html.parser')\n",
    "    # Extract text and href attributes for all articles\n",
    "    articles_data = []\n",
    "    articles = dataset_soup.find_all('article')\n",
    "    for article in articles:\n",
    "        text = article.h4.text.strip()\n",
    "        href = article.a['href']\n",
    "        articles_data.append({'dataset': text, 'dataset_url': href})\n",
    "        \n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(articles_data)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_huggingface_languages(huggingface_languages_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>ISO Code</th>\n",
       "      <th>Datasets Link</th>\n",
       "      <th>Models Link</th>\n",
       "      <th>Datasets Number</th>\n",
       "      <th>Model Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EnglishEnglish</td>\n",
       "      <td>en</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=en</td>\n",
       "      <td>7816</td>\n",
       "      <td>34499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chinese中文</td>\n",
       "      <td>zh</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=zh</td>\n",
       "      <td>924</td>\n",
       "      <td>3496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FrenchFrançais</td>\n",
       "      <td>fr</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=fr</td>\n",
       "      <td>824</td>\n",
       "      <td>3240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SpanishEspañol</td>\n",
       "      <td>es</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=es</td>\n",
       "      <td>646</td>\n",
       "      <td>2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RussianРусский</td>\n",
       "      <td>ru</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=ru</td>\n",
       "      <td>619</td>\n",
       "      <td>1752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>Southern Luri</td>\n",
       "      <td>luz</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=luz</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>Argentine Sign Language</td>\n",
       "      <td>aed</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=aed</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>Simte</td>\n",
       "      <td>smt</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=smt</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>Chilean Sign Language</td>\n",
       "      <td>csg</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=csg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>Kanauji</td>\n",
       "      <td>bjj</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=bjj</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2046 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Language ISO Code  \\\n",
       "0              EnglishEnglish       en   \n",
       "1                   Chinese中文       zh   \n",
       "2              FrenchFrançais       fr   \n",
       "3              SpanishEspañol       es   \n",
       "4              RussianРусский       ru   \n",
       "...                       ...      ...   \n",
       "2041            Southern Luri      luz   \n",
       "2042  Argentine Sign Language      aed   \n",
       "2043                    Simte      smt   \n",
       "2044    Chilean Sign Language      csg   \n",
       "2045                  Kanauji      bjj   \n",
       "\n",
       "                                          Datasets Link  \\\n",
       "0     https://huggingface.co/datasets?language=langu...   \n",
       "1     https://huggingface.co/datasets?language=langu...   \n",
       "2     https://huggingface.co/datasets?language=langu...   \n",
       "3     https://huggingface.co/datasets?language=langu...   \n",
       "4     https://huggingface.co/datasets?language=langu...   \n",
       "...                                                 ...   \n",
       "2041  https://huggingface.co/datasets?language=langu...   \n",
       "2042  https://huggingface.co/datasets?language=langu...   \n",
       "2043  https://huggingface.co/datasets?language=langu...   \n",
       "2044  https://huggingface.co/datasets?language=langu...   \n",
       "2045  https://huggingface.co/datasets?language=langu...   \n",
       "\n",
       "                                     Models Link  Datasets Number  \\\n",
       "0      https://huggingface.co/models?language=en             7816   \n",
       "1      https://huggingface.co/models?language=zh              924   \n",
       "2      https://huggingface.co/models?language=fr              824   \n",
       "3      https://huggingface.co/models?language=es              646   \n",
       "4      https://huggingface.co/models?language=ru              619   \n",
       "...                                          ...              ...   \n",
       "2041  https://huggingface.co/models?language=luz                1   \n",
       "2042  https://huggingface.co/models?language=aed                1   \n",
       "2043  https://huggingface.co/models?language=smt                1   \n",
       "2044  https://huggingface.co/models?language=csg                1   \n",
       "2045  https://huggingface.co/models?language=bjj                1   \n",
       "\n",
       "      Model Number  \n",
       "0            34499  \n",
       "1             3496  \n",
       "2             3240  \n",
       "3             2525  \n",
       "4             1752  \n",
       "...            ...  \n",
       "2041            14  \n",
       "2042             4  \n",
       "2043            15  \n",
       "2044             3  \n",
       "2045            14  \n",
       "\n",
       "[2046 rows x 6 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests on finding datasets for one language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stats = process_huggingface_datasets('https://huggingface.co/datasets?language=language:ofs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tatoeba</td>\n",
       "      <td>/datasets/tatoeba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lbourdois/language_tags</td>\n",
       "      <td>/datasets/lbourdois/language_tags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lbourdois/panlex</td>\n",
       "      <td>/datasets/lbourdois/panlex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dataset                        dataset_url\n",
       "0                  tatoeba                  /datasets/tatoeba\n",
       "1  lbourdois/language_tags  /datasets/lbourdois/language_tags\n",
       "2         lbourdois/panlex         /datasets/lbourdois/panlex"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with more datasets and more languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_huggingface_datasets(dataset_url, df = None):\n",
    "    '''\n",
    "    This function recursively retrieves dataset URLs from the Hugging Face website, starting from a given URL. \n",
    "    It iterates through all pages, extracts dataset names and URLs, and returns a list of dataset URLs.\n",
    "    '''\n",
    "    if df is None:\n",
    "        df = pd.DataFrame(columns=['dataset', 'dataset_url'])\n",
    "\n",
    "    dataset_request = requests.get(dataset_url).text\n",
    "    dataset_soup = BeautifulSoup(dataset_request, 'html.parser')\n",
    "    # Extract text and href attributes for all articles\n",
    "    articles_data = []\n",
    "    articles = dataset_soup.find_all('article')\n",
    "    for article in articles:\n",
    "        text = article.h4.text.strip()\n",
    "        href = article.a['href']\n",
    "        articles_data.append({'dataset': text, 'dataset_url': href})\n",
    "        \n",
    "\n",
    "    # Convert to DataFrame\n",
    "    temp_df = pd.DataFrame(articles_data)\n",
    "    print('first_df!')\n",
    "    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "    sections = dataset_soup.find_all('section')[-1]\n",
    "    next_page_link = sections.find('nav').find_all('a')[-1].get('href')\n",
    "    if next_page_link: \n",
    "        next_page_url = f'https://huggingface.co/datasets{next_page_link}'\n",
    "        return find_huggingface_datasets(next_page_url, df)\n",
    "    else: \n",
    "        print('language_done!')\n",
    "        return df['dataset_url'].tolist()\n",
    "    \n",
    "\n",
    "def find_earliest_commit(model_name):\n",
    "    '''\n",
    "    This function retrieves the commit history of a model from the Hugging Face website. \n",
    "    It identifies the earliest commit timestamp if available.\n",
    "    '''\n",
    "    soup = BeautifulSoup(requests.get(f'https://huggingface.co{model_name}').text, 'html.parser')\n",
    "    hrefs = [a['href'] for a in soup.find_all('a', class_ = 'tab-alternate')]\n",
    "    commits_href = ['https://huggingface.co' + url for url in hrefs if '/tree/main' in url]\n",
    "    if commits_href:\n",
    "        commits_href_history = commits_href[0].replace('tree', 'commits')\n",
    "        commits_soup = BeautifulSoup(requests.get(commits_href_history).text, 'html.parser')\n",
    "        time_elements = commits_soup.find_all('time')\n",
    "        datetimes = [time['datetime'] for time in time_elements]\n",
    "        processed_datetime = [datetime.fromisoformat(dt_str) for dt_str in datetimes]\n",
    "        if processed_datetime:\n",
    "            return min(processed_datetime)\n",
    "    else:\n",
    "        print('commits_not_found')\n",
    "        return 'nothing'\n",
    "    \n",
    "\n",
    "def find_earliest_datetime_pls(lst):\n",
    "    datetimes = [item for item in lst if isinstance(item, datetime)]\n",
    "    earliest_datetime = min(datetimes) if datetimes else None\n",
    "    return earliest_datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the tab alternate with tree main - from that one get the oldest of all dates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not storing anything for now! \n",
    "\n",
    "## What if at the beginning they were all uploaded together?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try on small dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>ISO Code</th>\n",
       "      <th>Datasets Link</th>\n",
       "      <th>Models Link</th>\n",
       "      <th>Datasets Number</th>\n",
       "      <th>Model Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>LuxembourgishLëtzebuergesch</td>\n",
       "      <td>lb</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=lb</td>\n",
       "      <td>56</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Yue Chinese</td>\n",
       "      <td>yue</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=yue</td>\n",
       "      <td>55</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Central Kurdish</td>\n",
       "      <td>ckb</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=ckb</td>\n",
       "      <td>55</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Asturian</td>\n",
       "      <td>ast</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=ast</td>\n",
       "      <td>55</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Scottish GaelicGàidhlig</td>\n",
       "      <td>gd</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=gd</td>\n",
       "      <td>54</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Language ISO Code  \\\n",
       "100  LuxembourgishLëtzebuergesch       lb   \n",
       "101                  Yue Chinese      yue   \n",
       "102              Central Kurdish      ckb   \n",
       "103                     Asturian      ast   \n",
       "104      Scottish GaelicGàidhlig       gd   \n",
       "\n",
       "                                         Datasets Link  \\\n",
       "100  https://huggingface.co/datasets?language=langu...   \n",
       "101  https://huggingface.co/datasets?language=langu...   \n",
       "102  https://huggingface.co/datasets?language=langu...   \n",
       "103  https://huggingface.co/datasets?language=langu...   \n",
       "104  https://huggingface.co/datasets?language=langu...   \n",
       "\n",
       "                                    Models Link  Datasets Number  Model Number  \n",
       "100   https://huggingface.co/models?language=lb               56           273  \n",
       "101  https://huggingface.co/models?language=yue               55           134  \n",
       "102  https://huggingface.co/models?language=ckb               55            72  \n",
       "103  https://huggingface.co/models?language=ast               55            83  \n",
       "104   https://huggingface.co/models?language=gd               54           233  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_df!\n",
      "first_df!\n",
      "language_done!\n",
      "first_df!\n",
      "first_df!\n",
      "language_done!\n",
      "first_df!\n",
      "first_df!\n",
      "language_done!\n",
      "first_df!\n",
      "first_df!\n",
      "language_done!\n",
      "first_df!\n",
      "first_df!\n",
      "language_done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/rf53f4q13351lmy9q5ygvhdm0000gp/T/ipykernel_65867/388238344.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_small['all_datasets'] = df_small['Datasets Link'].apply(lambda url: find_huggingface_datasets(url))\n"
     ]
    }
   ],
   "source": [
    "df_small['all_datasets'] = df_small['Datasets Link'].apply(lambda url: find_huggingface_datasets(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>ISO Code</th>\n",
       "      <th>Datasets Link</th>\n",
       "      <th>Models Link</th>\n",
       "      <th>Datasets Number</th>\n",
       "      <th>Model Number</th>\n",
       "      <th>all_datasets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>LuxembourgishLëtzebuergesch</td>\n",
       "      <td>lb</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=lb</td>\n",
       "      <td>56</td>\n",
       "      <td>273</td>\n",
       "      <td>[/datasets/CohereForAI/xP3x, /datasets/wikimed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Yue Chinese</td>\n",
       "      <td>yue</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=yue</td>\n",
       "      <td>55</td>\n",
       "      <td>134</td>\n",
       "      <td>[/datasets/CohereForAI/xP3x, /datasets/wikimed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Central Kurdish</td>\n",
       "      <td>ckb</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=ckb</td>\n",
       "      <td>55</td>\n",
       "      <td>72</td>\n",
       "      <td>[/datasets/CohereForAI/xP3x, /datasets/wikimed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Asturian</td>\n",
       "      <td>ast</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=ast</td>\n",
       "      <td>55</td>\n",
       "      <td>83</td>\n",
       "      <td>[/datasets/CohereForAI/xP3x, /datasets/wikimed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Scottish GaelicGàidhlig</td>\n",
       "      <td>gd</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=gd</td>\n",
       "      <td>54</td>\n",
       "      <td>233</td>\n",
       "      <td>[/datasets/CohereForAI/xP3x, /datasets/wikimed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Language ISO Code  \\\n",
       "100  LuxembourgishLëtzebuergesch       lb   \n",
       "101                  Yue Chinese      yue   \n",
       "102              Central Kurdish      ckb   \n",
       "103                     Asturian      ast   \n",
       "104      Scottish GaelicGàidhlig       gd   \n",
       "\n",
       "                                         Datasets Link  \\\n",
       "100  https://huggingface.co/datasets?language=langu...   \n",
       "101  https://huggingface.co/datasets?language=langu...   \n",
       "102  https://huggingface.co/datasets?language=langu...   \n",
       "103  https://huggingface.co/datasets?language=langu...   \n",
       "104  https://huggingface.co/datasets?language=langu...   \n",
       "\n",
       "                                    Models Link  Datasets Number  \\\n",
       "100   https://huggingface.co/models?language=lb               56   \n",
       "101  https://huggingface.co/models?language=yue               55   \n",
       "102  https://huggingface.co/models?language=ckb               55   \n",
       "103  https://huggingface.co/models?language=ast               55   \n",
       "104   https://huggingface.co/models?language=gd               54   \n",
       "\n",
       "     Model Number                                       all_datasets  \n",
       "100           273  [/datasets/CohereForAI/xP3x, /datasets/wikimed...  \n",
       "101           134  [/datasets/CohereForAI/xP3x, /datasets/wikimed...  \n",
       "102            72  [/datasets/CohereForAI/xP3x, /datasets/wikimed...  \n",
       "103            83  [/datasets/CohereForAI/xP3x, /datasets/wikimed...  \n",
       "104           233  [/datasets/CohereForAI/xP3x, /datasets/wikimed...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try on even smaller data for date finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_small[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/rf53f4q13351lmy9q5ygvhdm0000gp/T/ipykernel_65867/2688348931.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample['earliest_update'] = df_sample['all_datasets'].apply(lambda x: [find_earliest_commit(item) for item in x])\n"
     ]
    }
   ],
   "source": [
    "df_sample['earliest_update'] = df_sample['all_datasets'].apply(lambda x: [find_earliest_commit(item) for item in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>ISO Code</th>\n",
       "      <th>Datasets Link</th>\n",
       "      <th>Models Link</th>\n",
       "      <th>Datasets Number</th>\n",
       "      <th>Model Number</th>\n",
       "      <th>all_datasets</th>\n",
       "      <th>earliest_update</th>\n",
       "      <th>earliest_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>LuxembourgishLëtzebuergesch</td>\n",
       "      <td>lb</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=lb</td>\n",
       "      <td>56</td>\n",
       "      <td>273</td>\n",
       "      <td>[/datasets/CohereForAI/xP3x, /datasets/wikimed...</td>\n",
       "      <td>[2023-05-25 21:13:23, 2023-11-21 22:11:34, 202...</td>\n",
       "      <td>2021-03-08 20:57:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Language ISO Code  \\\n",
       "100  LuxembourgishLëtzebuergesch       lb   \n",
       "\n",
       "                                         Datasets Link  \\\n",
       "100  https://huggingface.co/datasets?language=langu...   \n",
       "\n",
       "                                   Models Link  Datasets Number  Model Number  \\\n",
       "100  https://huggingface.co/models?language=lb               56           273   \n",
       "\n",
       "                                          all_datasets  \\\n",
       "100  [/datasets/CohereForAI/xP3x, /datasets/wikimed...   \n",
       "\n",
       "                                       earliest_update   earliest_datetime  \n",
       "100  [2023-05-25 21:13:23, 2023-11-21 22:11:34, 202... 2021-03-08 20:57:23  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/rf53f4q13351lmy9q5ygvhdm0000gp/T/ipykernel_65867/3200975511.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sample['earliest_datetime'] = df_sample['earliest_update'].apply(find_earliest_datetime_pls)\n"
     ]
    }
   ],
   "source": [
    "df_sample['earliest_datetime'] = df_sample['earliest_update'].apply(find_earliest_datetime_pls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>ISO Code</th>\n",
       "      <th>Datasets Link</th>\n",
       "      <th>Models Link</th>\n",
       "      <th>Datasets Number</th>\n",
       "      <th>Model Number</th>\n",
       "      <th>all_datasets</th>\n",
       "      <th>earliest_update</th>\n",
       "      <th>earliest_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>LuxembourgishLëtzebuergesch</td>\n",
       "      <td>lb</td>\n",
       "      <td>https://huggingface.co/datasets?language=langu...</td>\n",
       "      <td>https://huggingface.co/models?language=lb</td>\n",
       "      <td>56</td>\n",
       "      <td>273</td>\n",
       "      <td>[/datasets/CohereForAI/xP3x, /datasets/wikimed...</td>\n",
       "      <td>[2023-05-25 21:13:23, 2023-11-21 22:11:34, 202...</td>\n",
       "      <td>2021-03-08 20:57:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Language ISO Code  \\\n",
       "100  LuxembourgishLëtzebuergesch       lb   \n",
       "\n",
       "                                         Datasets Link  \\\n",
       "100  https://huggingface.co/datasets?language=langu...   \n",
       "\n",
       "                                   Models Link  Datasets Number  Model Number  \\\n",
       "100  https://huggingface.co/models?language=lb               56           273   \n",
       "\n",
       "                                          all_datasets  \\\n",
       "100  [/datasets/CohereForAI/xP3x, /datasets/wikimed...   \n",
       "\n",
       "                                       earliest_update   earliest_datetime  \n",
       "100  [2023-05-25 21:13:23, 2023-11-21 22:11:34, 202... 2021-03-08 20:57:23  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #div = article.find('div').get_text(strip=True)\n",
    "        #this part does not work very well yet...(the downloads and likes one) - also: they are already sorted by trending....\n",
    "        #likes = re.findall(r'\\b\\d+\\b', div)[0]\n",
    "        #downloads = re.findall(r'\\b\\d+\\b', div)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_next_page_url(soup):\n",
    "    sections = soup.find_all('section')[-1]\n",
    "    if sections:\n",
    "        next_page_link = last_section.find('nav').find_all('a')[-1].get('href')\n",
    "    return next_page_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data_per_language(language_url):\n",
    "    language_file = requests.get(language_url)\n",
    "    if language_file.status_code == 200:\n",
    "        soup = BeautifulSoup(language_file.text, 'html.parser')\n",
    "        next_page_url = extract_next_page_url(soup) \n",
    "        while next_page_url:\n",
    "            next_file = requests.get(\"https://huggingface.co\" + next_page_url)\n",
    "            if language_file.status_code == 200:\n",
    "                new_soup = BeautifulSoup(language_file.text, 'html.parser')\n",
    "                return new_soup\n",
    "            else:\n",
    "                print('Error: Unable to fetch language URL:', language_url)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
